import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile

st.set_page_config(page_title="Snatch Exam Pro", layout="wide")
st.title("ğŸ‹ï¸ Ù†Ø¸Ø§Ù… ØªÙ‚ÙŠÙŠÙ… Ø±ÙØ¹Ø© Ø§Ù„Ø®Ø·Ù Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ (15 Ø¯Ø±Ø¬Ø©)")

mp_pose = mp.solutions.pose
pose = mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.7)

video_file = st.file_uploader("Ø§Ø±ÙØ¹ ÙÙŠØ¯ÙŠÙˆ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø·Ø§Ù„Ø¨ (ØªØµÙˆÙŠØ± Ø¬Ø§Ù†Ø¨ÙŠ ÙÙ‚Ø·)", type=["mp4", "mov", "avi"])

if video_file:
    tfile = tempfile.NamedTemporaryFile(delete=False) 
    tfile.write(video_file.read())
    cap = cv2.VideoCapture(tfile.name)
    st_frame = st.empty()
    
    # Ù…ØµÙÙˆÙØ© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ§Ù„Ø£Ø¹Ù„Ø§Ù…
    error_flags = {"hip_high": False, "hip_low": False, "early_back": False, "shallow_catch": False, "unstable": False}
    error_images = {}
    movement_started = False
    initial_wrist_y = None
    max_catch_depth = 0 # Ù„ØªØªØ¨Ø¹ Ø£Ù‚ØµÙ‰ Ù†Ø²ÙˆÙ„ Ù„Ù„Ø­ÙˆØ¶

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break

        h, w, _ = frame.shape
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(frame_rgb)

        if results.pose_landmarks:
            lm = results.pose_landmarks.landmark
            def get_p(idx): return int(lm[idx].x * w), int(lm[idx].y * h)
            
            sh, hip, knee, wrist, ankle = get_p(12), get_p(24), get_p(26), get_p(16), get_p(28)

            # 1. ÙƒØ´Ù Ø¨Ø¯Ø¡ Ø§Ù„Ø­Ø±ÙƒØ©
            if initial_wrist_y is None: initial_wrist_y = lm[16].y
            if not movement_started and abs(lm[16].y - initial_wrist_y) > 0.03:
                movement_started = True

            # --- Ø£. ÙˆÙ‚ÙØ© Ø§Ù„Ø§Ø³ØªØ¹Ø¯Ø§Ø¯ (5 Ø¯Ø±Ø¬Ø§Øª) ---
            if not movement_started:
                if lm[24].y < lm[12].y + 0.05 and not error_flags["hip_high"]:
                    error_flags["hip_high"] = True
                    img_err = frame.copy()
                    cv2.arrowedLine(img_err, hip, (hip[0], hip[1] + 60), (0, 0, 255), 6)
                    error_images["Ø§Ù„Ø§Ø³ØªØ¹Ø¯Ø§Ø¯"] = {"img": img_err, "tip": "Ø§Ù„Ø­ÙˆØ¶ Ù…Ø±ØªÙØ¹ Ø¬Ø¯Ø§Ù‹Ø› Ø§Ø®ÙØ¶ Ø§Ù„Ø­ÙˆØ¶ Ù„ØªØ¨Ø¯Ø£ Ø§Ù„Ø³Ø­Ø¨ Ø¨Ù‚ÙˆØ© Ø§Ù„Ø³Ø§Ù‚ÙŠÙ†."}
                elif lm[24].y > lm[26].y - 0.05 and not error_flags["hip_low"]:
                    error_flags["hip_low"] = True
                    img_err = frame.copy()
                    cv2.arrowedLine(img_err, hip, (hip[0], hip[1] - 60), (0, 0, 255), 6)
                    error_images["Ø§Ù„Ø§Ø³ØªØ¹Ø¯Ø§Ø¯"] = {"img": img_err, "tip": "Ø§Ù„Ø­ÙˆØ¶ Ù…Ù†Ø®ÙØ¶ Ø¬Ø¯Ø§Ù‹Ø› Ø§Ø±ÙØ¹Ù‡ Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ù„ØªØ¬Ù†Ø¨ ÙˆØ¶Ø¹ÙŠØ© Ø§Ù„Ù‚Ø±ÙØµØ§Ø¡."}

            # --- Ø¨. Ø§Ù„Ø³Ø­Ø¨Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ (3 Ø¯Ø±Ø¬Ø§Øª) ---
            elif movement_started and wrist[1] > knee[1]:
                if lm[24].y > lm[12].y + 0.22 and not error_flags["early_back"]:
                    error_flags["early_back"] = True
                    img_err = frame.copy()
                    cv2.line(img_err, sh, (sh[0], sh[1]-80), (0, 255, 255), 6)
                    error_images["Ø§Ù„Ø³Ø­Ø¨Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰"] = {"img": img_err, "tip": "Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ ØµØ¯Ø±Ùƒ Ù…Ø±ØªÙØ¹Ø§Ù‹Ø› Ø§Ù„Ø­ÙˆØ¶ ÙŠØ±ØªÙØ¹ Ø£Ø³Ø±Ø¹ Ù…Ù† Ø§Ù„Ù„Ø§Ø²Ù…."}

            # --- Ø¬. Ø§Ù„Ø³Ù‚ÙˆØ· ØªØ­Øª Ø§Ù„Ø«Ù‚Ù„ (5 Ø¯Ø±Ø¬Ø§Øª) ---
            if movement_started:
                # ØªØªØ¨Ø¹ Ø£Ù‚ØµÙ‰ Ø¹Ù…Ù‚ Ù„Ù„Ø­ÙˆØ¶
                if lm[24].y > max_catch_depth: max_catch_depth = lm[24].y
                
                # Ø¥Ø°Ø§ Ø§Ù†ØªÙ‡Øª Ø§Ù„Ø±ÙØ¹Ø© ÙˆÙ„Ù… ÙŠÙ†Ø²Ù„ Ø§Ù„Ø­ÙˆØ¶ Ø£Ø³ÙÙ„ Ø§Ù„Ø±ÙƒØ¨Ø©
                if max_catch_depth < lm[26].y and wrist[1] < sh[1]:
                    error_flags["shallow_catch"] = True

            # --- Ø¯. Ø§Ù„ÙˆÙ‚ÙˆÙ ÙˆØ§Ù„Ø«Ø¨Ø§Øª (2 Ø¯Ø±Ø¬Ø©) ---
            # Ù‚ÙŠØ§Ø³ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø£ÙÙ‚ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ù…Ø¹ØµÙ… ÙˆØ§Ù„ÙƒØ¹Ø¨ Ø¹Ù†Ø¯ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø±ÙØ¹Ø©
            if movement_started and wrist[1] < sh[1]: # Ø§Ù„Ù…Ø¹ØµÙ… ÙÙˆÙ‚ Ø§Ù„Ø±Ø£Ø³
                if abs(lm[16].x - lm[28].x) > 0.15:
                    error_flags["unstable"] = True

        st_frame.image(frame, channels="BGR", use_column_width=True)
    cap.release()

    # --- Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ---
    s_setup = 2 if (error_flags["hip_high"] or error_flags["hip_low"]) else 5
    s_pull = 1 if error_flags["early_back"] else 3
    s_catch = 2 if error_flags["shallow_catch"] else 5
    s_stable = 0 if error_flags["unstable"] else 2
    total = s_setup + s_pull + s_catch + s_stable

    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    st.divider()
    st.header(f"Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„Ø·Ø§Ù„Ø¨: {total} / 15")
    
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Ø§Ù„Ø§Ø³ØªØ¹Ø¯Ø§Ø¯", f"{s_setup}/5")
    c2.metric("Ø§Ù„Ø³Ø­Ø¨Ø© 1", f"{s_pull}/3")
    c3.metric("Ø§Ù„Ø³Ù‚ÙˆØ·", f"{s_catch}/5")
    c4.metric("Ø§Ù„Ø«Ø¨Ø§Øª", f"{s_stable}/2")

    if error_images:
        st.subheader("ğŸ“¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¨ØµØ±ÙŠ")
        for key, data in error_images.items():
            col_a, col_b = st.columns([1, 1])
            with col_a: st.image(data["img"], channels="BGR")
            with col_b: st.error(f"Ø®Ø·Ø£ ÙÙŠ {key}"); st.info(data["tip"])
