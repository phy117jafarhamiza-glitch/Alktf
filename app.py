import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
st.set_page_config(page_title="Snatch Pro Evaluator", layout="wide")

# Ø±Ø³Ø§Ù„Ø© ØªÙ†Ø¨ÙŠÙ‡ÙŠØ© ØªØ¸Ù‡Ø± ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
st.warning("âš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø© Ù‡Ø§Ù…Ø©: Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙ‚ÙŠÙŠÙ… Ø¯Ù‚ÙŠÙ‚ØŒ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„ØªØµÙˆÙŠØ± Ù…Ù† Ø§Ù„Ø¬Ø§Ù†Ø¨ (Side View) ÙˆØ¨Ø´ÙƒÙ„ Ø£ÙÙ‚ÙŠ ØªÙ…Ø§Ù…Ø§Ù‹.")
st.title("ğŸ‹ï¸ Ù†Ø¸Ø§Ù… ØªÙ‚ÙŠÙŠÙ… Ø±ÙØ¹Ø© Ø§Ù„Ø®Ø·Ù ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ")

mp_pose = mp.solutions.pose
pose = mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.7)

def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    if angle > 180.0: angle = 360 - angle
    return angle

video_file = st.file_uploader("Ù‚Ù… Ø¨Ø±ÙØ¹ ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø±ÙØ¹Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù‡Ù†Ø§", type=["mp4", "mov", "avi"])

if video_file:
    tfile = tempfile.NamedTemporaryFile(delete=False) 
    tfile.write(video_file.read())
    cap = cv2.VideoCapture(tfile.name)
    
    st_frame = st.empty()
    
    # Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙˆØ§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª
    scores = {"setup": 5, "first_pull": 3, "catch": 5, "stability": 2}
    feedbacks = []
    max_path_deviation = 0
    path_points = []

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break

        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(frame_rgb)

        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            h, w, _ = frame.shape
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]
            hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]
            knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]
            wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]
            ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]

            # --- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØªØ­Ø¯ÙŠØ¯ Ù…ÙƒØ§Ù†Ù‡Ø§ ---
            
            # 1. Ø®Ø·Ø£ ÙˆÙ‚ÙØ© Ø§Ù„Ø§Ø³ØªØ¹Ø¯Ø§Ø¯
            back_angle = calculate_angle(shoulder, hip, knee)
            if back_angle < 35 or back_angle > 75:
                if "ÙˆØ¶Ø¹ Ø§Ù„Ø­ÙˆØ¶ Ø®Ø§Ø·Ø¦ ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©" not in feedbacks:
                    feedbacks.append("ÙˆØ¶Ø¹ Ø§Ù„Ø­ÙˆØ¶ Ø®Ø§Ø·Ø¦ ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© (Ù…Ù†Ø®ÙØ¶ Ø¬Ø¯Ø§Ù‹ Ø£Ùˆ Ù…Ø±ØªÙØ¹ Ø¬Ø¯Ø§Ù‹)")
                    scores["setup"] -= 2

            # 2. Ø®Ø·Ø£ Ø§Ù„Ø³Ø­Ø¨Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ (ØªÙ‚ÙˆØ³ Ø§Ù„Ø¸Ù‡Ø±)
            if back_angle > 85 and wrist[1] > knee[1]:
                if "Ø±ÙØ¹ Ø§Ù„Ø¸Ù‡Ø± Ù…Ø¨ÙƒØ±Ø§Ù‹" not in feedbacks:
                    feedbacks.append("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø³Ø­Ø¨Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ù‚Ù…Øª Ø¨Ø±ÙØ¹ Ø§Ù„Ø¸Ù‡Ø± Ù‚Ø¨Ù„ Ø¹Ø¨ÙˆØ± Ø§Ù„Ø¨Ø§Ø± Ù„Ù„Ø±ÙƒØ¨Ø©")
                    scores["first_pull"] -= 1

            # 3. Ø®Ø·Ø£ Ù…Ø³Ø§Ø± Ø§Ù„Ø¨Ø§Ø± (Ø§Ù„Ø§Ø¨ØªØ¹Ø§Ø¯ Ø¹Ù† Ø§Ù„Ø¬Ø³Ù…)
            if len(path_points) > 0:
                deviation = abs(wrist[0] - ankle[0])
                if deviation > 0.15: # Ø¥Ø°Ø§ Ø§Ø¨ØªØ¹Ø¯ Ø§Ù„Ø¨Ø§Ø± Ø¹Ù† Ø®Ø· Ø§Ù„ÙƒØ§Ø­Ù„ Ø¨Ù…Ø³Ø§ÙØ© ÙƒØ¨ÙŠØ±Ø©
                    cv2.putText(frame, "BAR DISTANCE ERROR!", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)
                    if "Ø§Ù„Ø¨Ø§Ø± Ø¨Ø¹ÙŠØ¯ Ø¹Ù† Ø§Ù„Ø¬Ø³Ù…" not in feedbacks:
                        feedbacks.append("Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ÙÙ†ÙŠ: Ø§Ù„Ø¨Ø§Ø± ÙŠØ¨ØªØ¹Ø¯ Ø¹Ù† Ø¬Ø³Ù…Ùƒ Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ± (Looping)")
                        scores["catch"] -= 1

            # Ø±Ø³Ù… Ø§Ù„Ù…Ø³Ø§Ø± ÙˆØ§Ù„Ù†Ù‚Ø§Ø·
            cx, cy = int(wrist[0] * w), int(wrist[1] * h)
            path_points.append((cx, cy))
            for i in range(1, len(path_points)):
                cv2.line(frame, path_points[i-1], path_points[i], (0, 255, 0), 2)

        st_frame.image(frame, channels="BGR", use_column_width=True)

    cap.release()

    # --- Ø¹Ø±Ø¶ Ù„ÙˆØ­Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ---
    st.divider()
    total_score = sum(scores.values())
    st.header(f"Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {total_score} / 15")
    
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ğŸ“Š ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª")
        st.write(f"âœ… Ø§Ù„Ø§Ø³ØªØ¹Ø¯Ø§Ø¯: {scores['setup']}/5")
        st.write(f"âœ… Ø§Ù„Ø³Ø­Ø¨Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: {scores['first_pull']}/3")
        st.write(f"âœ… Ø§Ù„Ø³Ù‚ÙˆØ·: {scores['catch']}/5")
        st.write(f"âœ… Ø§Ù„Ø«Ø¨Ø§Øª: {scores['stability']}/2")
        
    with col2:
        st.subheader("âŒ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…ÙƒØªØ´ÙØ©")
        if feedbacks:
            for error in feedbacks:
                st.error(error)
        else:
            st.success("Ø£Ø¯Ø§Ø¡ Ù…Ù…ØªØ§Ø²! Ù„Ù… ÙŠØªÙ… Ø±ØµØ¯ Ø£Ø®Ø·Ø§Ø¡ ÙÙ†ÙŠØ© ÙƒØ¨Ø±Ù‰.")
