import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
import tempfile

st.set_page_config(page_title="Snatch Visual Coach", layout="wide")
st.title("๐๏ธ ูุฏุฑุจ ุงูุฎุทู: ุชุตุญูุญ ุงูุฃุฎุทุงุก ุจุงูุฑุณู ุงูุชูุถูุญู")

mp_pose = mp.solutions.pose
pose = mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.7)
mp_drawing = mp.solutions.drawing_utils

video_file = st.file_uploader("ุงุฑูุน ููุฏูู ุงูุฑูุนุฉ ุงูุฌุงูุจู", type=["mp4", "mov", "avi"])

if video_file:
    tfile = tempfile.NamedTemporaryFile(delete=False) 
    tfile.write(video_file.read())
    cap = cv2.VideoCapture(tfile.name)
    st_frame = st.empty()
    
    error_flags = {"hip_high": False, "hip_low": False, "early_back": False}
    initial_wrist_y = None
    movement_started = False

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break

        h, w, _ = frame.shape
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(frame_rgb)

        if results.pose_landmarks:
            lm = results.pose_landmarks.landmark
            
            # ุชุญููู ุงูุฅุญุฏุงุซูุงุช ูููุงุท ุจูุณููุฉ ููุฑุณู
            def get_pix(landmark_idx):
                return int(lm[landmark_idx].x * w), int(lm[landmark_idx].y * h)

            sh_p = get_pix(12) # ุงููุชู
            hip_p = get_pix(24) # ุงูุญูุถ
            knee_p = get_pix(26) # ุงูุฑูุจุฉ
            wrist_p = get_pix(16) # ุงููุนุตู (ุงูุจุงุฑ)

            # --- ูุดู ุจุฏุก ุงูุญุฑูุฉ ---
            if initial_wrist_y is None: initial_wrist_y = lm[16].y
            if not movement_started and abs(lm[16].y - initial_wrist_y) > 0.02:
                movement_started = True

            # --- ุงูุฑุณู ุงูุชูุถูุญู ูุชุตุญูุญ ุงูุฃุฎุทุงุก ---
            
            # 1. ุชุตุญูุญ ูููุฉ ุงูุงุณุชุนุฏุงุฏ (ูุจู ุงูุญุฑูุฉ)
            if not movement_started:
                # ุฅุฐุง ูุงู ุงูุญูุถ ูุฑุชูุนุงู ุฌุฏุงู (ูุฑูุจ ูู ูุณุชูู ุงููุชู)
                if lm[24].y < lm[12].y + 0.05:
                    error_flags["hip_high"] = True
                    # ุฑุณู ุณูู ุชูุถูุญู ูุฎูุถ ุงูุญูุถ
                    cv2.arrowedLine(frame, hip_p, (hip_p[0], hip_p[1] + 50), (0, 0, 255), 5)
                    cv2.putText(frame, "LOWER YOUR HIP", (hip_p[0]+10, hip_p[1]+30), 1, 1.5, (0,0,255), 2)
                
                # ุฅุฐุง ูุงู ุงูุญูุถ ููุฎูุถุงู ุฌุฏุงู
                elif lm[24].y > lm[26].y - 0.05:
                    error_flags["hip_low"] = True
                    # ุฑุณู ุณูู ุชูุถูุญู ูุฑูุน ุงูุญูุถ
                    cv2.arrowedLine(frame, hip_p, (hip_p[0], hip_p[1] - 50), (0, 0, 255), 5)
                    cv2.putText(frame, "RAISE YOUR HIP", (hip_p[0]+10, hip_p[1]-30), 1, 1.5, (0,0,255), 2)

            # 2. ุชุตุญูุญ ุงูุณุญุจุฉ ุงูุฃููู (ุจุนุฏ ุงูุญุฑูุฉ)
            else:
                if lm[24].y > lm[12].y + 0.2: # ุงูุตุฏุฑ ูุณูุท ูุงูุญูุถ ูุฑุชูุน
                    error_flags["early_back"] = True
                    # ุฑุณู ุฎุท ุชูุถูุญู ููุตุฏุฑ ููุธูุฑ ุฃูู ูุฌุจ ุฃู ูุฑุชูุน
                    cv2.line(frame, sh_p, (sh_p[0], sh_p[1]-60), (0, 255, 255), 5)
                    cv2.putText(frame, "KEEP CHEST UP", (sh_p[0]-50, sh_p[1]-70), 1, 1.5, (0,255,255), 2)

            # ุฑุณู ุงููููู ุงูุนุธูู ุงูุฃุณุงุณู
            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        st_frame.image(frame, channels="BGR", use_column_width=True)
    cap.release()

    st.success("ุงูุชูู ุงูุชุญููู ุงูููุชุจู. ุฑุงุฌุน ุงูุฑุณููุงุช ุงูุญูุฑุงุก ูุงูุตูุฑุงุก ุนูู ุงูููุฏูู ูุชุตุญูุญ ูุถุนูุชู.")
